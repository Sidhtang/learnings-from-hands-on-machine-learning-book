{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODfLsj6t0/3XVNSEB/zQhY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sidhtang/learnings-from-hands-on-machine-learning-book/blob/main/iplementation_of_googlenet_cnn_for_mnist_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import datasets, layers, models, losses, Model\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ],
      "metadata": {
        "id": "RMJYE5k6lsQz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#then, the data is loaded as in the LeNet implementation. One important notice is that the original GoogLeNet model receives images with the size 224 x 224 x 3 however, MNIST images are 28 x 28. The third axis is expanded and repeated 3 times to make image sizes 28 x 28 x 3. It will be then resized at the first layer of the model to 224 x 224 x 3."
      ],
      "metadata": {
        "id": "5_-NU_R8lsTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test) = datasets.mnist.load_data()\n",
        "x_train = tf.pad(x_train, [[0, 0], [2,2], [2,2]])/255\n",
        "x_test = tf.pad(x_test, [[0, 0], [2,2], [2,2]])/255\n",
        "x_train = tf.expand_dims(x_train, axis=3, name=None)\n",
        "x_test = tf.expand_dims(x_test, axis=3, name=None)\n",
        "x_train = tf.repeat(x_train, 3, axis=3)\n",
        "x_test = tf.repeat(x_test, 3, axis=3)\n",
        "x_val = x_train[-2000:,:,:,:]\n",
        "y_val = y_train[-2000:]\n",
        "x_train = x_train[:-2000,:,:,:]\n",
        "y_train = y_train[:-2000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nufjRLujlsWV",
        "outputId": "bc96635d-fff0-49a3-ea2a-de302f85a007"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inception(x,\n",
        "              filters_1x1,\n",
        "              filters_3x3_reduce,\n",
        "              filters_3x3,\n",
        "              filters_5x5_reduce,\n",
        "              filters_5x5,\n",
        "              filters_pool):\n",
        "  path1 = layers.Conv2D(filters_1x1, (1, 1), padding='same',    activation='relu')(x)\n",
        "  path2 = layers.Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)\n",
        "  path2 = layers.Conv2D(filters_3x3, (1, 1), padding='same', activation='relu')(path2)\n",
        "  path3 = layers.Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)\n",
        "  path3 = layers.Conv2D(filters_5x5, (1, 1), padding='same', activation='relu')(path3)\n",
        "  path4 = layers.MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "  path4 = layers.Conv2D(filters_pool, (1, 1), padding='same', activation='relu')(path4)\n",
        "  return tf.concat([path1, path2, path3, path4], axis=3)"
      ],
      "metadata": {
        "id": "7tXVVq77lsZM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = layers.Input(shape=(32, 32, 3))\n",
        "input_tensor = layers.experimental.preprocessing.Resizing(224, 224, interpolation=\"bilinear\", input_shape=x_train.shape[1:])(inp)\n",
        "x = layers.Conv2D(64, 7, strides=2, padding='same', activation='relu')(input_tensor)\n",
        "x = layers.MaxPooling2D(3, strides=2)(x)\n",
        "x = layers.Conv2D(64, 1, strides=1, padding='same', activation='relu')(x)\n",
        "x = layers.Conv2D(192, 3, strides=1, padding='same', activation='relu')(x)\n",
        "x = layers.MaxPooling2D(3, strides=2)(x)\n",
        "x = inception(x, filters_1x1=64, filters_3x3_reduce=96, filters_3x3=128, filters_5x5_reduce=16, filters_5x5=32, filters_pool=32)\n",
        "x = inception(x, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=192, filters_5x5_reduce=32, filters_5x5=96, filters_pool=64)\n",
        "x = layers.MaxPooling2D(3, strides=2)(x)\n",
        "x = inception(x, filters_1x1=192, filters_3x3_reduce=96, filters_3x3=208, filters_5x5_reduce=16, filters_5x5=48, filters_pool=64)\n",
        "aux1 = layers.AveragePooling2D((5, 5), strides=3)(x)\n",
        "aux1 =layers.Conv2D(128, 1, padding='same', activation='relu')(aux1)\n",
        "aux1 = layers.Flatten()(aux1)\n",
        "aux1 = layers.Dense(1024, activation='relu')(aux1)\n",
        "aux1 = layers.Dropout(0.7)(aux1)\n",
        "aux1 = layers.Dense(10, activation='softmax')(aux1)\n",
        "x = inception(x, filters_1x1=160, filters_3x3_reduce=112, filters_3x3=224, filters_5x5_reduce=24, filters_5x5=64, filters_pool=64)\n",
        "x = inception(x, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=256, filters_5x5_reduce=24, filters_5x5=64, filters_pool=64)\n",
        "x = inception(x, filters_1x1=112, filters_3x3_reduce=144, filters_3x3=288, filters_5x5_reduce=32, filters_5x5=64, filters_pool=64)\n",
        "aux2 = layers.AveragePooling2D((5, 5), strides=3)(x)\n",
        "aux2 =layers.Conv2D(128, 1, padding='same', activation='relu')(aux2)\n",
        "aux2 = layers.Flatten()(aux2)\n",
        "aux2 = layers.Dense(1024, activation='relu')(aux2)\n",
        "aux2 = layers.Dropout(0.7)(aux2)\n",
        "aux2 = layers.Dense(10, activation='softmax')(aux2)\n",
        "x = inception(x, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320, filters_5x5_reduce=32, filters_5x5=128, filters_pool=128)\n",
        "x = layers.MaxPooling2D(3, strides=2)(x)\n",
        "x = inception(x, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320, filters_5x5_reduce=32, filters_5x5=128, filters_pool=128)\n",
        "x = inception(x, filters_1x1=384, filters_3x3_reduce=192, filters_3x3=384, filters_5x5_reduce=48, filters_5x5=128, filters_pool=128)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "out = layers.Dense(10, activation='softmax')(x)\n"
      ],
      "metadata": {
        "id": "4_qiRDiDrk0Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs = inp, outputs = [out, aux1, aux2])"
      ],
      "metadata": {
        "id": "7KYMIqV5rk3o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs = inp, outputs = [out, aux1, aux2], name='GoogLeNet') # Give the model a name\n",
        "model.compile(optimizer='adam',\n",
        "              loss={'dense_4': 'sparse_categorical_crossentropy', # Use actual output layer names\n",
        "                    'dense_1': 'sparse_categorical_crossentropy',\n",
        "                    'dense_3': 'sparse_categorical_crossentropy'},\n",
        "              loss_weights={'dense_4': 1, 'dense_1': 0.3, 'dense_3': 0.3}, # Use actual output layer names\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(x_train, [y_train, y_train, y_train], validation_data=(x_val, [y_val, y_val, y_val]), batch_size=64, epochs=40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyJwnv7Nlskz",
        "outputId": "e192702d-559d-4489-b123-ec2fdf556b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "128/907 [===>..........................] - ETA: 2:14:51 - loss: 3.2004 - dense_4_loss: 2.1540 - dense_1_loss: 1.6754 - dense_3_loss: 1.8123 - dense_4_accuracy: 0.1760 - dense_1_accuracy: 0.3914 - dense_3_accuracy: 0.3326"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oP_LXbBkwlUs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}